{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset 'no1' already exists; use `fiftyone.load_dataset()` to load an existing dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m splits \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[39m# Load the dataset, using tags to mark the samples in each split\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m dataset \u001b[39m=\u001b[39m fo\u001b[39m.\u001b[39;49mDataset(name)\n\u001b[1;32m     12\u001b[0m dataset\u001b[39m.\u001b[39mlimit(\u001b[39m100\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m splits:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/fiftyone/core/singletons.py:33\u001b[0m, in \u001b[0;36mDatasetSingleton.__call__\u001b[0;34m(cls, name, _create, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     _create\n\u001b[1;32m     29\u001b[0m     \u001b[39mor\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_instances\n\u001b[1;32m     30\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_instances[name]\u001b[39m.\u001b[39mdeleted\n\u001b[1;32m     31\u001b[0m ):\n\u001b[1;32m     32\u001b[0m     instance \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m     instance\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name\u001b[39m=\u001b[39;49mname, _create\u001b[39m=\u001b[39;49m_create, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m     name \u001b[39m=\u001b[39m instance\u001b[39m.\u001b[39mname  \u001b[39m# `__init__` may have changed `name`\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_instances[name] \u001b[39m=\u001b[39m instance\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/fiftyone/core/dataset.py:241\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, name, persistent, overwrite, _create, _virtual, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m     delete_dataset(name)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _create:\n\u001b[0;32m--> 241\u001b[0m     doc, sample_doc_cls, frame_doc_cls \u001b[39m=\u001b[39m _create_dataset(\n\u001b[1;32m    242\u001b[0m         name, persistent\u001b[39m=\u001b[39;49mpersistent, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     doc, sample_doc_cls, frame_doc_cls \u001b[39m=\u001b[39m _load_dataset(\n\u001b[1;32m    246\u001b[0m         name, virtual\u001b[39m=\u001b[39m_virtual\n\u001b[1;32m    247\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/fiftyone/core/dataset.py:5546\u001b[0m, in \u001b[0;36m_create_dataset\u001b[0;34m(name, persistent, _patches, _frames, _clips, _src_collection)\u001b[0m\n\u001b[1;32m   5537\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_dataset\u001b[39m(\n\u001b[1;32m   5538\u001b[0m     name,\n\u001b[1;32m   5539\u001b[0m     persistent\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5543\u001b[0m     _src_collection\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   5544\u001b[0m ):\n\u001b[1;32m   5545\u001b[0m     \u001b[39mif\u001b[39;00m dataset_exists(name):\n\u001b[0;32m-> 5546\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   5547\u001b[0m             (\n\u001b[1;32m   5548\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m already exists; use `fiftyone.load_dataset()` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5549\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mto load an existing dataset\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5550\u001b[0m             )\n\u001b[1;32m   5551\u001b[0m             \u001b[39m%\u001b[39m name\n\u001b[1;32m   5552\u001b[0m         )\n\u001b[1;32m   5554\u001b[0m     _id \u001b[39m=\u001b[39m ObjectId()\n\u001b[1;32m   5556\u001b[0m     sample_collection_name \u001b[39m=\u001b[39m _make_sample_collection_name(\n\u001b[1;32m   5557\u001b[0m         _id, patches\u001b[39m=\u001b[39m_patches, frames\u001b[39m=\u001b[39m_frames, clips\u001b[39m=\u001b[39m_clips\n\u001b[1;32m   5558\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset 'no1' already exists; use `fiftyone.load_dataset()` to load an existing dataset"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "name = \"no1\"\n",
    "dataset_dir = \"/usr/src/datasets/n130064t_fiftyone\"\n",
    "\n",
    "# The splits to load\n",
    "#splits = [\"train\", \"val\"]\n",
    "splits = [\"train\"]\n",
    "\n",
    "# Load the dataset, using tags to mark the samples in each split\n",
    "#dataset = fo.Dataset(name)\n",
    "dataset = fo.load_dataset(name)\n",
    "dataset.limit(100)\n",
    "\n",
    "for split in splits:\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=split,\n",
    ")\n",
    "\n",
    "\n",
    "# View summary info about the dataset\n",
    "#print(dataset)\n",
    "#\n",
    "## Print the first few samples in the dataset\n",
    "#print(dataset.head())\n",
    "session = fo.launch_app(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
