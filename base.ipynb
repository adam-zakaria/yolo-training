{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/src/datasets/n51848v removed\n",
      "/usr/src/datasets/n51848v created\n",
      "/usr/src/datasets/n51848v/base created\n",
      "/usr/src/datasets/n51848v/base/images created\n",
      "/usr/src/datasets/n51848v/base/labels created\n",
      "Using /usr/src/raw_datasets/nightowls/nightowls_validation.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "imgIds\n",
      "51848\n",
      "imgIds with positive bboxes\n",
      "50866\n",
      "total labels: 14930\n",
      "class distribution: Counter({'0': 9380, '3': 5001, '1': 303, '2': 246})\n",
      "ls /usr/src/datasets/n51848v/base/images | wc -l ; ls /usr/src/datasets/n51848v/base/labels | wc -l\n",
      "50866\n",
      "50866\n",
      "/usr/src/datasets/c5000v removed\n",
      "/usr/src/datasets/c5000v created\n",
      "/usr/src/datasets/c5000v/base created\n",
      "/usr/src/datasets/c5000v/base/images created\n",
      "/usr/src/datasets/c5000v/base/labels created\n",
      "Using /usr/src/raw_datasets/coco/annotations/instances_val2017.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "imgIds\n",
      "5000\n",
      "imgIds with positive bboxes\n",
      "5000\n",
      "total labels: 36781\n",
      "class distribution: Counter({'0': 11004, '2': 1932, '56': 1791, '73': 1161, '39': 1025, '41': 899, '60': 697, '9': 637, '45': 626, '26': 540, '14': 440, '8': 430, '7': 415, '13': 413, '25': 413, '19': 380, '46': 379, '24': 371, '3': 371, '51': 371, '18': 361, '58': 343, '40': 343, '54': 338, '33': 336, '43': 326, '1': 316, '50': 316, '55': 316, '28': 303, '62': 288, '49': 287, '5': 285, '53': 285, '65': 283, '75': 277, '17': 273, '37': 269, '22': 268, '74': 267, '32': 263, '67': 262, '57': 261, '20': 255, '27': 254, '44': 253, '30': 241, '47': 239, '23': 232, '63': 231, '38': 225, '71': 225, '16': 218, '42': 215, '15': 202, '77': 191, '6': 190, '61': 179, '36': 179, '48': 177, '59': 163, '66': 153, '35': 148, '34': 146, '69': 143, '4': 143, '52': 127, '72': 126, '29': 115, '64': 106, '10': 101, '11': 75, '21': 71, '31': 69, '12': 60, '79': 57, '68': 55, '76': 36, '78': 11, '70': 9})\n",
      "ls /usr/src/datasets/c5000v/base/images | wc -l ; ls /usr/src/datasets/c5000v/base/labels | wc -l\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "def confirm_files_origin(dir0, dir1):\n",
    "    #confirm files in dir0 come from dir1\n",
    "    dir1_images = os.listdir(dir1)\n",
    "    dir0_images = os.listdir(dir0)\n",
    "    for f in dir1_images:\n",
    "        if f not in dir0_images:\n",
    "            print(f'{f} not in {dir0_images}')\n",
    "            return \n",
    "    print(\"All image files originate from the correct source dataset\")\n",
    "    print(\"Note: label files are derived from annotations.json\")\n",
    "    return\n",
    "\n",
    "def print_num_labels(dir):\n",
    "    fs = os.listdir(dir)\n",
    "    num_labels = 0\n",
    "    for f in fs:\n",
    "        filename_nightowls = os.path.join(dir, f)\n",
    "        ls = \"\" \n",
    "        with open(filename_nightowls, encoding='latin-1') as fx:\n",
    "            for l in fx:\n",
    "                num_labels += 1\n",
    "    print(f'total labels: {num_labels}') \n",
    "\n",
    "def distribution(label_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    read all label files\n",
    "    count each label\n",
    "    print distribution\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    for f in os.listdir(label_dir):\n",
    "        with open(os.path.join(label_dir, f)) as f1:\n",
    "            for l in f1:\n",
    "                label = l.split()[0]\n",
    "                c.update([label])\n",
    "    print(f'class distribution: {c}')\n",
    "    return c \n",
    "\n",
    "def coco_to_yolo_bb(x1, y1, w, h, image_w, image_h):\n",
    "    return [((2*x1 + w)/(2*image_w)) , ((2*y1 + h)/(2*image_h)), w/image_w, h/image_h]\n",
    "\n",
    "def mkdir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def rmdir(dataset_dir):\n",
    "    if os.path.exists(dataset_dir):\n",
    "        shutil.rmtree(dataset_dir)\n",
    "\n",
    "def get_cat_data(coco):\n",
    "    cats = coco.loadCats(coco.getCatIds())\n",
    "    cat_map = {}\n",
    "    for i,cat in enumerate(cats):\n",
    "        cat_map[cat['id']] = i\n",
    "    catIds = coco.getCatIds()\n",
    "    return catIds, cat_map\n",
    "\n",
    "def get_random_img_ids(numImgs,coco):\n",
    "    imgIds = coco.getImgIds()\n",
    "    random.shuffle(imgIds)\n",
    "\n",
    "    print(f'imgIds')\n",
    "    print(len(imgIds))\n",
    "    #imgIds = list(filter(lambda imgId: img_id_has_annotation(imgId, coco), imgIds))\n",
    "    #print(f'imgIds with annotations')\n",
    "    #print(len(imgIds))\n",
    "    imgIds = list(filter(lambda imgId: img_id_has_positive_bboxes(imgId,coco), imgIds))\n",
    "    print(f'imgIds with positive bboxes')\n",
    "    print(len(imgIds))\n",
    "    #add a filter for labels outside frame\n",
    "    #have a discussion about these images probably\n",
    "    return imgIds[:numImgs]\n",
    "\n",
    "def img_id_has_positive_bboxes(imgId,coco):\n",
    "    annIds = coco.getAnnIds(imgIds=imgId)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    for ann in anns:\n",
    "        negative_bbox = False \n",
    "        for bbox_val in ann['bbox']:\n",
    "            if bbox_val < 0:\n",
    "                negative_bbox = True\n",
    "        if negative_bbox == True:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def img_id_has_annotation(imgId,coco):\n",
    "    annIds = coco.getAnnIds(imgIds=imgId)\n",
    "    if(len(annIds) > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def write_label_files(numImgs, cat_map, catIds, label_dir1, coco):\n",
    "    \"\"\"\n",
    "    Some images:\n",
    "    *Do not have annotations.\n",
    "    *Have negative bboxes\n",
    "    \"\"\"\n",
    "    imgIds = get_random_img_ids(numImgs,coco)\n",
    "\n",
    "    for imgId in imgIds:\n",
    "        img = coco.loadImgs(imgId)[0] #If only 1 imgId, len() = 1\n",
    "        label_dir = Path(label_dir1)\n",
    "        filename = img['file_name'].split('.')[0] + '.txt'\n",
    "        with open(label_dir/filename, 'w') as file:\n",
    "            annIds = coco.getAnnIds(imgIds = imgId, catIds=catIds)\n",
    "            anns = coco.loadAnns(annIds)\n",
    "            for i,ann in enumerate(anns):\n",
    "                x_center, y_center, width, height = coco_to_yolo_bb(*ann['bbox'], img['width'], img['height'])\n",
    "                file.write(f'{cat_map[ann[\"category_id\"]]} {x_center} {y_center} {width} {height}\\n')\n",
    "    return\n",
    "\n",
    "def copy_images_to_dataset_dir(src_image_dir, dest_image_dir, image_extension, src_label_dir):\n",
    "    \"\"\"\n",
    "    x number of labels are written to the labels dir by write_label_files(x)\n",
    "    This function copies the corresponding images into the sibling images dir, completing the dataset folder for YOLO training\n",
    "    \"\"\"\n",
    "    fs = os.listdir(src_label_dir)\n",
    "    for f in fs:\n",
    "        if f == '.DS_Store':\n",
    "            continue\n",
    "        src = str(src_image_dir/f.split('.')[0]) + image_extension\n",
    "        dest = str(dest_image_dir/ f.split('.')[0]) + image_extension\n",
    "        if os.path.isfile(src):\n",
    "            #shutil.copyfile(src, dest)\n",
    "            os.symlink(src, dest)\n",
    "        else:\n",
    "            print(f'{src} is not a file')\n",
    "    return\n",
    "\n",
    "def dataset_helper(dataset_name):\n",
    "    #i.e. [n, 2500, t]\n",
    "    [name, num_imgs, set] = re.split('(\\d+)', dataset_name)\n",
    "    if name == 'c':\n",
    "        file_extension = '.jpg'\n",
    "        if set == 't':\n",
    "            print('coco train set not download')\n",
    "            return\n",
    "        elif set == 'v':\n",
    "            src_img_dir = '/usr/src/raw_datasets/coco/val2017'\n",
    "            annotations_json_file = '/usr/src/raw_datasets/coco/annotations/instances_val2017.json'\n",
    "    if name == 'n' :\n",
    "        file_extension = '.png'\n",
    "        if set == 't':\n",
    "            src_img_dir = '/usr/src/raw_datasets/nightowls/nightowls_training'\n",
    "            annotations_json_file = '/usr/src/raw_datasets/nightowls/nightowls_training.json'\n",
    "        elif set == 'v':\n",
    "            src_img_dir = '/usr/src/raw_datasets/nightowls/nightowls_validation'\n",
    "            annotations_json_file = '/usr/src/raw_datasets/nightowls/nightowls_validation.json'\n",
    "\n",
    "    dataset_dir = f'/usr/src/datasets/{dataset_name}'\n",
    "    base_dir = f'{dataset_dir}/base'\n",
    "    label_dir =  f'{base_dir}/labels'\n",
    "    img_dir = f'{base_dir}/images'\n",
    "\n",
    "    rmdir(dataset_dir)\n",
    "    print(f'{dataset_dir} removed')\n",
    "\n",
    "    mkdir(dataset_dir)\n",
    "    mkdir(base_dir)\n",
    "    mkdir(label_dir)\n",
    "    mkdir(img_dir)\n",
    "    print(f'{dataset_dir} created')\n",
    "    print(f'{base_dir} created')\n",
    "    print(f'{img_dir} created')\n",
    "    print(f'{label_dir} created')\n",
    "\n",
    "    return src_img_dir, label_dir, img_dir, annotations_json_file, int(num_imgs), file_extension\n",
    "\n",
    "\n",
    "def produce_dataset(dataset_name):\n",
    "    src_img_dir, label_dir, img_dir, annotations_json_file, num_imgs, file_extension  = dataset_helper(dataset_name)\n",
    "\n",
    "    print(f'Using {annotations_json_file}')\n",
    "    coco=COCO(annotations_json_file)\n",
    "\n",
    "    catIds, cat_map = get_cat_data(coco)\n",
    "    write_label_files(num_imgs, cat_map, catIds, label_dir,coco) \n",
    "    copy_images_to_dataset_dir(Path(src_img_dir),Path(img_dir), file_extension, label_dir) #dataset/images\n",
    "\n",
    "    print_num_labels(label_dir)\n",
    "    distribution(label_dir)\n",
    "    print(f'ls {img_dir} | wc -l ; ls {label_dir} | wc -l')\n",
    "    os.system(f'ls {img_dir} | wc -l ; ls {label_dir} | wc -l')\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #maxes verified from papers or sites\n",
    "    #produce_dataset('n130064t') #max = 130064\n",
    "    #produce_dataset('n100t') #max = 130064\n",
    "    produce_dataset('n51848v') #max = 51848\n",
    "    produce_dataset('c5000v') #max = 5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
